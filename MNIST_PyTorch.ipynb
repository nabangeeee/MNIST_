{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWqQSdQBjtGi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transfroms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # GPU인지 CPU인지 확인\n",
        "torch.manual_seed(777) # cpu 연산 무작위 고정\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777) # 멀티 gpu 연산 무작위 고정\n",
        "print(device + \" is available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM7R3jDVFCvg",
        "outputId": "07b9c3f8-71e8-4607-cae2-c5e3d7a2fabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # 파라미터 설정 (최적화된 학습결과를 위해)\n",
        "learning_rate = 0.001 # 학습스텝의 크기\n",
        "batch_size = 100 # 하나의 소그룹에 속하는 데이터 수\n",
        "num_classes = 10\n",
        "epochs = 5 # 전체 트레이닝 셋이 신경망을 통과한 횟수"
      ],
      "metadata": {
        "id": "EXH0Z7k3FGuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터셋 로드\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transfroms.Compose([\n",
        "        transfroms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
        "    ])\n",
        ")\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transfroms.Compose([\n",
        "        transfroms.ToTensor() # 데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjhzv5CFkqaC",
        "outputId": "019b55e5-f903-41c2-dce5-86ade090d1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 85.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 26.4MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 66.0MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.05MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader, test_loader 생성\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "w4J4QBVHktbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input size를 알기 위해서\n",
        "examples = enumerate(train_set)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnmfcmb2kxjD",
        "outputId": "778644ce-cde1-4a9f-8da6-b142ac371b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self): # layer 정의\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        # input size = 28x28\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # input channel = 1 (흑백), filter = 10, kernel size = 5, zero padding = 0, stribe = 1\n",
        "        # ((W-K+2P)/S)+1 공식으로 인해 ((28-5+0)/1)+1=24 -> 24x24로 변환\n",
        "        # maxpooling하면 12x12\n",
        "\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # input channel = 1 (흑백), filter = 10, kernel size = 5, zero padding = 0, stribe = 1\n",
        "        # ((12-5+0)/1)+1=8 -> 8x8로 변환\n",
        "        # maxpooling하면 4x4\n",
        "\n",
        "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) # 랜덤하게 뉴런을 종료해서 학습을 방해해 학습이 학습용 데이터에 치우치는 현상을 막기 위해 사용\n",
        "        self.mp = nn.MaxPool2d(2)  # 오버피팅을 방지하고, 연산에 들어가는 자원을 줄이기 위해 maxpolling\n",
        "        self.fc1 = nn.Linear(320,100) # 4x4x20 vector로 flat한 것을 100개의 출력으로 변경\n",
        "        self.fc2 = nn.Linear(100,10) # 100개의 출력을 10개의 출력으로 변경\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = F.relu(self.mp(self.conv1(x))) # convolution layer 1번에 relu를 씌우고 maxpool, 결과값은 12x12x10\n",
        "        x = F.relu(self.mp(self.conv2(x))) # convolution layer 2번에 relu를 씌우고 maxpool, 결과값은 4x4x20\n",
        "        x = self.drop2D(x)\n",
        "        x = x.view(x.size(0), -1) # flat\n",
        "        x = self.fc1(x) # fc1 레이어에 삽입\n",
        "        x = self.fc2(x) # fc2 레이어에 삽입\n",
        "        return F.log_softmax(x) # fully-connected layer에 넣고 logsoftmax 적용\n"
      ],
      "metadata": {
        "id": "s96-aOCKk0kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet().to(device) # CNN instance 생성\n",
        "# Cost Function과 Optimizer 선택\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
      ],
      "metadata": {
        "id": "Elx0Z0Jkk3X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs): # epochs수만큼 반복\n",
        "    avg_cost = 0\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad() # 모든 model의 gradient 값을 0으로 설정\n",
        "        hypothesis = model(data) # 모델을 forward pass해 결과값 저장\n",
        "        cost = criterion(hypothesis, target) # output과 target의 loss 계산\n",
        "        cost.backward() # backward 함수를 호출해 gradient 계산\n",
        "        optimizer.step() # 모델의 학습 파라미터 갱신\n",
        "        avg_cost += cost / len(train_loader) # loss 값을 변수에 누적하고 train_loader의 개수로 나눔 = 평균\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW1hw-fVlAXL",
        "outputId": "0835928e-3682-4cdf-c478-df729af223e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-95b17c5db994>:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) # fully-connected layer에 넣고 logsoftmax 적용\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.317375064\n",
            "[Epoch:    2] cost = 0.114673778\n",
            "[Epoch:    3] cost = 0.0866675451\n",
            "[Epoch:    4] cost = 0.0750871301\n",
            "[Epoch:    5] cost = 0.0662997514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "model.eval() # evaluate mode로 전환 dropout 이나 batch_normalization 해제\n",
        "with torch.no_grad(): # grad 해제\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        out = model(data)\n",
        "        preds = torch.max(out.data, 1)[1] # 출력이 분류 각각에 대한 값으로 나타나기 때문에, 가장 높은 값을 갖는 인덱스를 추출\n",
        "        total += len(target) # 전체 클래스 개수\n",
        "        correct += (preds==target).sum().item() # 예측값과 실제값이 같은지 비교\n",
        "\n",
        "    print('Test Accuracy: ', 100.*correct/total, '%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPBp0WvjlDp3",
        "outputId": "07bda93f-dba3-474a-8a0d-cdc3c624511a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-95b17c5db994>:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) # fully-connected layer에 넣고 logsoftmax 적용\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  98.49 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J7ZY0iEe29Rk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}